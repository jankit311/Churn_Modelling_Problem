{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with features of a customer like nationality,gender,income,credit card,etc. We have to Predict that the person will leave the bank or Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpEWPHJVufy1"
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing dataset\n",
    "dataset=pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "X=dataset.iloc[:,3:13].values\n",
    "Y=dataset.iloc[:,13].values\n",
    "\n",
    "#changing the features like nationality,gender to fit in network\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "a=LabelEncoder()\n",
    "X[:,1]=a.fit_transform(X[:,1])  #Converted 3 nationality to 0,1,2\n",
    "X[:,2]=a.fit_transform(X[:,2])  #converted male,female to 0,1\n",
    "\n",
    "b=OneHotEncoder(categorical_features=[1])  #Label encoder gave 0,1,2 value to nationality which will effect network so converting to OneHot\n",
    "X=b.fit_transform(X).toarray()\n",
    "X=X[:,1:]  # Trimming one column of oneHot value as two column are sufficient to represent \n",
    "\n",
    "#Splitting dataset in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "\n",
    "#Scaling feature to same scale(0-1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building ANN with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0BDYxQfhUHM"
   },
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "#Initialisng ANN model\n",
    "model=Sequential()\n",
    "\n",
    "#Setting up layers\n",
    "\n",
    "#input layer\n",
    "model.add(Dense(units=6,activation='relu',kernel_initializer='uniform',input_dim=11))\n",
    "#hidden layer\n",
    "model.add(Dense(units=6,activation='relu',kernel_initializer='uniform')) #Uniform weight initialisiation\n",
    "#output layer\n",
    "model.add(Dense(units=1,activation='sigmoid',kernel_initializer='uniform')) #Output layer having sigmoid for binary classifiers and softmax for categorical classifiers\n",
    "#Compiling model\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']) #binary classifier->binary_crossentropy,categorical classifier->categorical_crossentropy\n",
    "#Training step\n",
    "model.fit(x_train,y_train,batch_size=30,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZXyaaE_ehYK8"
   },
   "outputs": [],
   "source": [
    "#test set prediction\n",
    "y_pred=model.predict(x_test)\n",
    "y_pred=(y_pred>0.5)\n",
    "\n",
    "# Predicting a single new observation\n",
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\"\"\"\n",
    "res = model.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "res = (res > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "-BUNson_h2Fb",
    "outputId": "e03dd846-bb83-4359-c78a-afa81ed7d33b"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier  #using scikit-learn with keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Function for Building deep net\n",
    "def Build_Network():\n",
    "  model=Sequential()\n",
    "  \n",
    "  model.add(Dense(units=6,activation='relu',kernel_initializer='uniform',input_dim=11))\n",
    "  model.add(Dense(units=6,activation='relu',kernel_initializer='uniform'))\n",
    "  model.add(Dense(units=1,activation='sigmoid',kernel_initializer='uniform'))\n",
    "  \n",
    "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model=KerasClassifier(build_fn=Build_Network,batch_size=10,epochs=100)\n",
    "accuracies=cross_val_score(estimator=model,X=x_train,y=y_train,cv=10,n_jobs=-1) #10-fold cross validation using all cpu's\n",
    "mean=accuracies.mean()\n",
    "variance=accuracies.std()\n",
    "print (mean)\n",
    "print (variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning and Improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DI9zo4Vwu0zP"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV  #for trying different combinations of hyperparameter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Function for deepnet with optimizer as parameter\n",
    "def Build_network(optimizer):\n",
    "  model=Sequential()\n",
    "  \n",
    "  model.add(Dense(units=6,activation='relu',kernel_initializer='uniform',input_dim=11))\n",
    "\n",
    "  model.add(Dense(units=6,activation='relu',kernel_initializer='uniform'))\n",
    "\n",
    "  model.add(Dense(units=1,activation='sigmoid',kernel_initializer='uniform'))\n",
    "  \n",
    "  model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "  return model\n",
    "model=KerasClassifier(build_fn=Build_network)\n",
    "hyper_param={'batch_size':[25,32],'epochs':[100,200],'optimizer':['adam','rmsprop']} # Hypermeters for trying\n",
    "grid_search=GridSearchCV(estimator=model,\n",
    "                        param_grid=hyper_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10) #10-fold coss validation with hperparameter tuning\n",
    "grid_search=grid_search.fit(x_train,y_train)\n",
    "best_param=grid_search.best_params_\n",
    "best_acc=grid_search.best_score_\n",
    "\n",
    "print(best_param)\n",
    "print(best_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
